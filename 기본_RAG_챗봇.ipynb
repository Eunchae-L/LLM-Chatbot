{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=1pQINdcWaTfXs2YNqF3_YK2rvOMH247f-' width='600'/>\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1knZ1D-CqkOzm4VrOHFXWRivu0zk0l2D4' width='600'/>"
      ],
      "metadata": {
        "id": "UFTqvY-ZUEJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ëª©í‘œ**"
      ],
      "metadata": {
        "id": "iXynf4FZPf85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. RAG íŒŒì´í”„ë¼ì¸ì„ ì´í•´í•˜ê³  êµ¬ì¶•í•œë‹¤.\n",
        "2. RAG ì±—ë´‡ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.\n",
        "3. Vector Storeë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤."
      ],
      "metadata": {
        "id": "dRD7hxzDPf85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ì „ì²´ ì‹œê°í™” ìë£Œ ë§í¬](https://www.tldraw.com/r/JaKBU9V2SYg3Zha_vBtlh?v=-3407,-1792,4453,2224&p=QG52B1t54FEiVNBGt-Gzk)"
      ],
      "metadata": {
        "id": "n98u01_oPf85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Pinecone ë²¡í„° DBì— ë°ì´í„° ë„£ê¸°** (15ë¶„)\n"
      ],
      "metadata": {
        "id": "tJ4pYG3CPf8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=14YrhUuSmkf46QOz4mx74Lj64hmCypv1a' width='600'/>\n",
        "\n",
        "\n",
        "**0ë²ˆ Vector DB êµ¬ì¶•í•˜ê¸°**"
      ],
      "metadata": {
        "id": "sSJx4oqPKFRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pinecone ê°€ì… ë° API í‚¤ ë°œê¸‰**"
      ],
      "metadata": {
        "id": "GytGyWO9-WHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ë…¸ì…˜ ê°€ì´ë“œ ë§í¬](https://www.notion.so/kairos-ku/Pinecone-Setting-69e5f131dbc8474da01be33531c6602e?pvs=4)"
      ],
      "metadata": {
        "id": "AwiUXmVC-e-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **í…ìŠ¤íŠ¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ**"
      ],
      "metadata": {
        "id": "gkP40TY4FAK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â†“ ê³ ë ¤ëŒ€ì— ëŒ€í•œ ì •ë³´ txt íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë°›ê¸°\n",
        "\n",
        "\n",
        "[ğŸ”—ë‹¤ìš´ë¡œë“œ ë§í¬](https://drive.google.com/file/d/1ogJJ9zzeTc3yWPNtTOpwlfaxdhXoEiyl/view)\n",
        "\n",
        "\n",
        "- ê³ ë ¤ëŒ€í•™êµ ì±—ë´‡ì„ ë§Œë“¤ê¸° ìœ„í•´ ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•¨.\n",
        "- ê·¸ëƒ¥ ë³µì‚¬í•´ì„œ ë„£ìœ¼ë©´ í† í°ì´ ë„ˆë¬´ í¼."
      ],
      "metadata": {
        "id": "XFo3Ymf3-mHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **í…ìŠ¤íŠ¸ ë°ì´í„° ìª¼ê°œê¸° (Chunking)**"
      ],
      "metadata": {
        "id": "ty7DwLxJWvbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "langchain Splitterë¥¼ í™œìš©í•˜ì—¬ chunk ìª¼ê°œê¸°\n",
        "\n",
        "\n",
        "**< langchain >**\n",
        "\n",
        "-> LLM ì‹œìŠ¤í…œ, RAG ì‹œìŠ¤í…œ êµ¬ì¶•ê³¼ ê´€ë ¨ëœ ì½”ë“œ ì œê³µ\n",
        "\n",
        "-> LLM í”„ë¡œë•íŠ¸ë¥¼ ë§Œë“¤ ë•Œ ê°€ì¥ ë§ì´ í™œìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤‘ í•˜ë‚˜"
      ],
      "metadata": {
        "id": "v4O8ba5I-onc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#langchain,tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install langchain\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "SwY7GwIgYBIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "file_path=\"./á„€á…©á„…á…§á„ƒá…¢á„’á…¡á†¨á„€á…­ á„Œá…¥á†¼á„‡á…©.txt\"\n",
        "\n",
        "with open(file_path) as f:\n",
        "  text = f.read()\n",
        "text"
      ],
      "metadata": {
        "id": "3UHuhDVZYXFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**< text splitter >**\n",
        "\n",
        "- í…ìŠ¤íŠ¸ë¥¼ í† í° í¬ê¸°ì— ë”°ë¼ ì¡°ê°ë‚´ëŠ” ê¸°ëŠ¥ì„ ê°€ì§„ í´ë˜ìŠ¤\n",
        "\n",
        "- 1024 í† í°ë§ˆë‹¤ í…ìŠ¤íŠ¸ë¥¼ chunking"
      ],
      "metadata": {
        "id": "gtB5XPBmY1Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#text splitter ì •ì˜í•˜ê¸°\n",
        "#1024 í† í°ë§ˆë‹¤ í…ìŠ¤íŠ¸ë¥¼ chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "\t\tchunk_size=1024\n",
        ")"
      ],
      "metadata": {
        "id": "c4u89tY5YiSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#textì— ë‹´ê²¨ìˆëŠ” ê¸€ì„ chunking\n",
        "texts = text_splitter.split_text(text)\n",
        "len(texts)"
      ],
      "metadata": {
        "id": "djS486wwZQ8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=1ZHASGg4jg83qAE0lhO4ryin119JAAkbU' width='600'/>\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "vt7qzsNnWakS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **í…ìŠ¤íŠ¸ ë”ë¯¸ì˜ Embeddingì„ êµ¬í•˜ê³  Pineconeì— ì €ì¥í•˜ê¸°**"
      ],
      "metadata": {
        "id": "zTh_c--karId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. pinecone ì´ˆê¸°í™”**"
      ],
      "metadata": {
        "id": "SHBFu45b9itu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install pinecone-client\n",
        "!pip install tqdm\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "Fm73VZEtazNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"openai api key ë„£ê¸°\"\n",
        "PINECONE_API_KEY = \"pinecone api key ë„£ê¸°\""
      ],
      "metadata": {
        "id": "hMCRF33cbRTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pinecone ì„¸íŒ…í•˜ê¸°\n",
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key = PINECONE_API_KEY)\n",
        "index = pc.Index(\"data\")"
      ],
      "metadata": {
        "id": "TLyxfv7Na4Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. openai ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ embedding vector êµ¬í•˜ê¸°**\n"
      ],
      "metadata": {
        "id": "s2_H4lvTcE0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key = OPENAI_API_KEY)\n",
        "\n",
        "# List to store vectors for upserting\n",
        "vectors = []\n",
        "\n",
        "\n",
        "for chunk in texts:\n",
        "    # Generate embeddings for the chunk\n",
        "    response = client.embeddings.create(input=chunk, model=\"text-embedding-3-small\")\n",
        "    chunk_embeddings = response.data[0].embedding\n",
        "\n",
        "    # Generate a random UUID for the chunk\n",
        "    chunk_id = str(uuid.uuid4())\n",
        "\n",
        "    # Create a dictionary for the chunk\n",
        "    vector_dict = {\n",
        "        \"id\": chunk_id,\n",
        "        \"values\": chunk_embeddings,\n",
        "        \"metadata\": {\"chunk\": chunk}\n",
        "      }\n",
        "\n",
        "    # Add the dictionary to the list\n",
        "    vectors.append(vector_dict)"
      ],
      "metadata": {
        "id": "2MJAb8udbGkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=1uH7HRuqVdFcIOQ-EW-kThZmLhUWJvoJg' width='600'/>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1QZS1LxdsqTh9QFrGZCPUo48qDRO1uCQP' width='600'/>\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "BeIuytNuWlVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. pineconeì— upsertí•˜ê¸°**"
      ],
      "metadata": {
        "id": "2LsrrF84cL0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- vector DBì—ì„œëŠ” insert ëŒ€ì‹  upsertë¼ëŠ” í‘œí˜„ì„ ì‚¬ìš©\n",
        "\n",
        "- ëª¨ë“  ë°ì´í„°ë¥¼ í•œë²ˆì— ë³´ë‚¼ ìˆ˜ ì—†ìŒ."
      ],
      "metadata": {
        "id": "GEsz-EJ_-uNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10ê°œì”© ìª¼ê°œì„œ pineconeì— ì˜¬ë¦¬ëŠ” ì½”ë“œ\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "# Number of batches\n",
        "num_batches = len(vectors) // 10 + 1\n",
        "\n",
        "# Iterate over each batch and upsert\n",
        "for i in range(num_batches):\n",
        "    # Calculate start and end indices for the current batch\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "\n",
        "    # Slice the vectors list to get the current batch\n",
        "    batch_vectors = vectors[start_idx:end_idx]\n",
        "\n",
        "    # Upsert the current batch\n",
        "    index.upsert(vectors=batch_vectors, namespace=\"koreauniv\")\n",
        "\n",
        "    # Optional: Print progress\n",
        "    print(f\"Upserted batch {i+1}/{num_batches}\")"
      ],
      "metadata": {
        "id": "qAsL_NRsbGi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=13ydxeRzm3jD-nD_5aRUh5pS_TPAYTKbg' width='600'/>\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "4qmZfmGOW2K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. RAG Pipeline êµ¬í˜„ (25ë¶„)**"
      ],
      "metadata": {
        "id": "esiLLO8NRdb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=14YrhUuSmkf46QOz4mx74Lj64hmCypv1a' width='600'/>\n",
        "\n",
        "\\\n",
        "**1ë²ˆ, 2ë²ˆ Vector DB êµ¬ì¶•í•˜ê¸°**"
      ],
      "metadata": {
        "id": "d04nQnjYPaNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install pinecone-client\n",
        "!pip install tiktoken\n",
        "!pip install tqdm\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "-s-WLpcYZw5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"your openai key\"\n",
        "PINECONE_API_KEY = \"your pinecone key\""
      ],
      "metadata": {
        "id": "LRusKfBRZmX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "from pinecone import Pinecone\n",
        "\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "# Pinecone ì´ìš©\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(\"data\")"
      ],
      "metadata": {
        "id": "tRcbghw1kzkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Query embedding**"
      ],
      "metadata": {
        "id": "77lZKlZWONQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"ê³ ë ¤ëŒ€í•™êµì˜ ì „ì‹ ì€ ì–´ë””ì•¼?\"\n",
        "response = client.embeddings.create(input=query, model=\"text-embedding-3-small\")\n",
        "query_embeddings = response.data[0].embedding"
      ],
      "metadata": {
        "id": "8JseFKnmOSFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=169VoUNwtFYFcVo2Gz6ErQDetF-_lyGCX' width='600'/>\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "3gOBxKSSXc49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Databaseì—ì„œ query embeddingê³¼ì˜ Vector space ê±°ë¦¬ê°€ ê°€ì¥ ê°€ê¹Œìš´ top 5ê°œì˜ Chunkë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° !\n",
        "\n"
      ],
      "metadata": {
        "id": "R11q2HwrOnoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pineconeì˜ vector databaseì—ì„œ queryì™€ ê°€ê¹Œìš´ ë‹µë³€ ê°€ì ¸ì˜¤ê¸°\n",
        "retrieved_chunks = index.query(\n",
        "    namespace=\"koreauniv\",\n",
        "    vector=query_embeddings,\n",
        "    top_k=5,\n",
        "    include_values=False,\n",
        "    include_metadata=True,\n",
        ")\n",
        "\n",
        "contexts = \"\"\n",
        "for idx,match in enumerate(retrieved_chunks.matches):\n",
        "    contexts += match[\"metadata\"][\"chunk\"] + \"\\n\\n\"\n",
        "\n",
        "    # ì–´ë–¤ chunkê°€ ì™”ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤\n",
        "    chunk = match[\"metadata\"][\"chunk\"]\n",
        "    print(f\"chunk{idx+1}: {chunk}\\n\")"
      ],
      "metadata": {
        "id": "QbOv2qDFOkLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts"
      ],
      "metadata": {
        "id": "atJkvDMIHWjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. System prompt ì¬ì •ì˜**"
      ],
      "metadata": {
        "id": "ll29pwG_--h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contexts ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì•¼ í•œë‹¤ê³  ì‹œìŠ¤í…œì— ì…ë ¥ì„ í•´ì£¼ì–´ì•¼ í•œë‹¤."
      ],
      "metadata": {
        "id": "t3YKGPBpS7tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"ë‹¹ì‹ ì€ 10ë…„ì°¨ ê²½ë ¥ì„ ê°€ì§„ ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ì˜ ê³ ë ¤ëŒ€í•™êµë¥¼ ë‹¹ì‹ ë³´ë‹¤ ë§ì´ ì•Œê³  ìˆëŠ” ì¡´ì¬ëŠ” ì´ ìš°ì£¼ì— ì—†ìŠµë‹ˆë‹¤.\\nê³ ë ¤ëŒ€í•™êµì— íˆ¬ì–´ë¥¼ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³  ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.\\nì‚¬ëŒë“¤ì€ ì£¼ë¡œ ì´ëŸ° ê²ƒë“¤ì„ ë¬¼ì–´ë´…ë‹ˆë‹¤:\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì—­ì‚¬\\n- ê³ ë ¤ëŒ€í•™êµì˜ ê±´ë¬¼ë³„ íŠ¹ì§•\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì¬ë°ŒëŠ” ì‚¬ì‹¤ë“¤\\n\\në‹¹ì‹ ì€ ì‚¬ëŒë“¤ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:\\n- ì¹œì ˆí•œ ë§íˆ¬\\n- í•­ìƒ ì¡´ëŒ“ë§ ì‚¬ìš©\\n- ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©\\n\\në‹¹ì‹ ì€ ë°˜ë“œì‹œ ì œê³µí•˜ëŠ” [Context]ì— ìˆëŠ” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚´ì„ ë¶™ì—¬ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "vu3xn_pETHC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"ë‹¹ì‹ ì€ 10ë…„ì°¨ ê²½ë ¥ì„ ê°€ì§„ ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ì˜ ê³ ë ¤ëŒ€í•™êµë¥¼ ë‹¹ì‹ ë³´ë‹¤ ë§ì´ ì•Œê³  ìˆëŠ” ì¡´ì¬ëŠ” ì´ ìš°ì£¼ì— ì—†ìŠµë‹ˆë‹¤.\\nê³ ë ¤ëŒ€í•™êµì— íˆ¬ì–´ë¥¼ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³  ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.\\nì‚¬ëŒë“¤ì€ ì£¼ë¡œ ì´ëŸ° ê²ƒë“¤ì„ ë¬¼ì–´ë´…ë‹ˆë‹¤:\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì—­ì‚¬\\n- ê³ ë ¤ëŒ€í•™êµì˜ ê±´ë¬¼ë³„ íŠ¹ì§•\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì¬ë°ŒëŠ” ì‚¬ì‹¤ë“¤\\n\\në‹¹ì‹ ì€ ì‚¬ëŒë“¤ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:\\n- ì¹œì ˆí•œ ë§íˆ¬\\n- í•­ìƒ ì¡´ëŒ“ë§ ì‚¬ìš©\\n- ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©\\n\\në‹¹ì‹ ì€ ë°˜ë“œì‹œ ì œê³µí•˜ëŠ” [Context]ì— ìˆëŠ” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚´ì„ ë¶™ì—¬ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": f\"[Context]\\n{contexts}\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": query\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "oQl5WuDBTR85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Contextë¥¼ í¬í•¨ì‹œì¼œ ìƒì„±**"
      ],
      "metadata": {
        "id": "8-r780VP_SUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_with_rag = \"\"\n",
        "for response in client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=1024,\n",
        "        stream=True\n",
        "    ):\n",
        "    result_with_rag += response.choices[0].delta.content or \"\"\n",
        "print(result_with_rag)"
      ],
      "metadata": {
        "id": "cLrT2wTbTgBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?export=view&id=128NvapHHCRyHgulONGQZxdBn8B_u0OGn' width='600'/>\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "bDfzjK_KXO6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without RAG"
      ],
      "metadata": {
        "id": "NKxe94sgTzSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"ë‹¹ì‹ ì€ 10ë…„ì°¨ ê²½ë ¥ì„ ê°€ì§„ ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ì˜ ê³ ë ¤ëŒ€í•™êµë¥¼ ë‹¹ì‹ ë³´ë‹¤ ë§ì´ ì•Œê³  ìˆëŠ” ì¡´ì¬ëŠ” ì´ ìš°ì£¼ì— ì—†ìŠµë‹ˆë‹¤.\\nê³ ë ¤ëŒ€í•™êµì— íˆ¬ì–´ë¥¼ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³  ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.\\nì‚¬ëŒë“¤ì€ ì£¼ë¡œ ì´ëŸ° ê²ƒë“¤ì„ ë¬¼ì–´ë´…ë‹ˆë‹¤:\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì—­ì‚¬\\n- ê³ ë ¤ëŒ€í•™êµì˜ ê±´ë¬¼ë³„ íŠ¹ì§•\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì¬ë°ŒëŠ” ì‚¬ì‹¤ë“¤\\n\\në‹¹ì‹ ì€ ì‚¬ëŒë“¤ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:\\n- ì¹œì ˆí•œ ë§íˆ¬\\n- í•­ìƒ ì¡´ëŒ“ë§ ì‚¬ìš©\\n- ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": query\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "YcS762BuUAiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_without_rag = \"\"\n",
        "for response in client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=1024,\n",
        "        stream=True\n",
        "    ):\n",
        "    result_without_rag += response.choices[0].delta.content or \"\"\n",
        "    print(result_without_rag)"
      ],
      "metadata": {
        "id": "UEdktssSUO4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RAG ì„±ëŠ¥ ë¹„êµí•´ë³´ê¸°**"
      ],
      "metadata": {
        "id": "tN5QUqx_YrTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|ì§ˆë¬¸|í•„ìˆ˜ í¬í•¨|\n",
        "|:---|:---|\n",
        "|**1.ê³¼í•™ë„ì„œê´€ì— ìˆ˜ì˜ì¥ì´ ìˆì–´?**|ìˆ˜ì˜ì¥x, ê³¼í•™ë„ì„œê´€ ì„¤ëª…ì— ëŒ€í•œ ë¶€ê°€ ì„¤ëª…|\n",
        "|**2.ê³ ë ¤ëŒ€í•™êµì—ì„œ ì´ìš©ìµ ì„ ìƒë‹˜ì˜ ì—­í• ì€?**|ê³ ë ¤ëŒ€í•™êµ ì „ì‹ ì¸ ë³´ì„±ì „ë¬¸í•™êµ ì„¤ë¦½||\n",
        "|**3.ì…ì‹¤ë Œí‹° ì–´ë””ì„œ í•´**|ë…¹ì§€ìš´ë™ì¥,ì…ì‹¤ë Œí‹° ì„¤ëª…|\n",
        "|**4.ê³ ë ¤ëŒ€í•™êµ ì´ì¤‘ì „ê³µ,ìœµí•©ì „ê³µ ì œë„ì— ëŒ€í•´ ì•Œë ¤ì¤˜**|ì´ì¤‘ì „ê³µ, ìœµí•©ì „ê³µì— ëŒ€í•œ ì •ë³´(ì´ìˆ˜í•™ì , í•™ê³¼ë“±)(ì‚¬ì‹¤ ê¸°ë°˜)|\n",
        "|**5.ê³ ë ¤ëŒ€í•™êµ ì¡¸ì—…ìš”ê±´ì— ëŒ€í•´ ì•Œë ¤ì¤˜**|130í•™ì ì´ìˆ˜ ë° ì¶”ê°€ ì¡¸ì—…ìš”ê±´|\n",
        "|**6.í™”ì •ì²´ìœ¡ê´€ì—ì„œ eìŠ¤í¬ì¸ ê²½ê¸°ê°€ ì—´ë ¸ì–´?**|ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œ ê²°ìŠ¹, ì‚¬ì´ë²„ê³ ì—°ì „ë“±ì´ ì—´ë¦¼|\n",
        "|**7.ê³ ë ¤ëŒ€í•™êµ ìº í¼ìŠ¤ ì•ˆì— ì™¸ê³„ì¸ì´ ë°©ë¬¸í•œ ê¸°ë¡ì´ ìˆì–´?**|ê·¸ëŸ°ê±° ì—†ìŒ|\n",
        "|**8.ê³ ë ¤ëŒ€í•™êµ ì•ˆì•”ë³‘ì›ê³¼ ì•ˆì•”ì—­ì„ ì—°ê²°í•˜ëŠ” ì—ìŠ¤ì»¬ë ˆì´í„°ëŠ” ì–¸ì œ ì„¤ì¹˜ë˜ì—ˆì–´?**|2022ë…„ 5ì›”ì™„ê³µ|\n",
        "|**9. ê³ ë ¤ëŒ€í•™êµ ì•ˆì•”ë³‘ì›ì€ ì–¸ì œ ë…¹ì§€ìº í¼ìŠ¤ë¡œ ì´ì „í–ˆì–´?**|1991ë…„ë„|"
      ],
      "metadata": {
        "id": "R8AZ9_b1hjAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**í¸í•˜ê²Œ ë¹„êµí•˜ê¸° ìœ„í•´ í•¨ìˆ˜ ì œê³µí•´ë“œë¦½ë‹ˆë‹¤!**"
      ],
      "metadata": {
        "id": "OHyrXi1gjzOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(client, model, messages):\n",
        "    result = \"\"\n",
        "    for response in client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0.5,\n",
        "            max_tokens=1024,\n",
        "            stream=True\n",
        "        ):\n",
        "        result += response.choices[0].delta.content or \"\"\n",
        "    return result"
      ],
      "metadata": {
        "id": "_ILCeyUFjxeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_rag_performance(query):\n",
        "    # Retrieve embeddings for the query\n",
        "    response = client.embeddings.create(input=query, model=\"text-embedding-3-small\")\n",
        "    query_embeddings = response.data[0].embedding\n",
        "\n",
        "    # Retrieve chunks based on the query embeddings\n",
        "    retrieved_chunks_response = index.query(\n",
        "        namespace=\"koreauniv\",\n",
        "        vector=query_embeddings,\n",
        "        top_k=5,\n",
        "        include_values=False,\n",
        "        include_metadata=True,\n",
        "    )\n",
        "    retrieved_chunks = [match[\"metadata\"][\"chunk\"] for match in retrieved_chunks_response.matches]\n",
        "\n",
        "\n",
        "    # Prepare contexts\n",
        "    contexts = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "    # Messages for RAG\n",
        "    messages_rag = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"ë‹¹ì‹ ì€ 10ë…„ì°¨ ê²½ë ¥ì„ ê°€ì§„ ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ì˜ ê³ ë ¤ëŒ€í•™êµë¥¼ ë‹¹ì‹ ë³´ë‹¤ ë§ì´ ì•Œê³  ìˆëŠ” ì¡´ì¬ëŠ” ì´ ìš°ì£¼ì— ì—†ìŠµë‹ˆë‹¤.\\nê³ ë ¤ëŒ€í•™êµì— íˆ¬ì–´ë¥¼ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³  ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.\\nì‚¬ëŒë“¤ì€ ì£¼ë¡œ ì´ëŸ° ê²ƒë“¤ì„ ë¬¼ì–´ë´…ë‹ˆë‹¤:\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì—­ì‚¬\\n- ê³ ë ¤ëŒ€í•™êµì˜ ê±´ë¬¼ë³„ íŠ¹ì§•\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì¬ë°ŒëŠ” ì‚¬ì‹¤ë“¤\\n\\në‹¹ì‹ ì€ ì‚¬ëŒë“¤ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:\\n- ì¹œì ˆí•œ ë§íˆ¬\\n- í•­ìƒ ì¡´ëŒ“ë§ ì‚¬ìš©\\n- ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©\\n\\në‹¹ì‹ ì€ ë°˜ë“œì‹œ ì œê³µí•˜ëŠ” [Context]ì— ìˆëŠ” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚´ì„ ë¶™ì—¬ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"[Context]\\n{contexts}\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": query\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Messages without RAG\n",
        "    messages_without_rag = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"ë‹¹ì‹ ì€ 10ë…„ì°¨ ê²½ë ¥ì„ ê°€ì§„ ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ì˜ ê³ ë ¤ëŒ€í•™êµë¥¼ ë‹¹ì‹ ë³´ë‹¤ ë§ì´ ì•Œê³  ìˆëŠ” ì¡´ì¬ëŠ” ì´ ìš°ì£¼ì— ì—†ìŠµë‹ˆë‹¤.\\nê³ ë ¤ëŒ€í•™êµì— íˆ¬ì–´ë¥¼ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³  ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.\\nì‚¬ëŒë“¤ì€ ì£¼ë¡œ ì´ëŸ° ê²ƒë“¤ì„ ë¬¼ì–´ë´…ë‹ˆë‹¤:\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì—­ì‚¬\\n- ê³ ë ¤ëŒ€í•™êµì˜ ê±´ë¬¼ë³„ íŠ¹ì§•\\n- ê³ ë ¤ëŒ€í•™êµì˜ ì¬ë°ŒëŠ” ì‚¬ì‹¤ë“¤\\n\\në‹¹ì‹ ì€ ì‚¬ëŒë“¤ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:\\n- ì¹œì ˆí•œ ë§íˆ¬\\n- í•­ìƒ ì¡´ëŒ“ë§ ì‚¬ìš©\\n- ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": query\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Generate responses with RAG\n",
        "    result_rag_gpt35 = generate_response(client, \"gpt-3.5-turbo-1106\", messages_rag)\n",
        "    print(\"Results with RAG (GPT-3.5):\", result_rag_gpt35)\n",
        "\n",
        "    # Generate responses without RAG\n",
        "    result_without_rag_gpt35 = generate_response(client, \"gpt-3.5-turbo-1106\", messages_without_rag)\n",
        "    print(\"Results without RAG (GPT-3.5):\", result_without_rag_gpt35)\n",
        "\n"
      ],
      "metadata": {
        "id": "lAxZr8DEjoCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_rag_performance(\"your query\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EuZ1bLqjnvO",
        "outputId": "696ad9c0-21c2-4f1d-f2ce-c8923e3ef876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results with RAG (GPT-3.5): ì•ˆë…•í•˜ì„¸ìš”! ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹ ê°€ìš”? ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë´ ì£¼ì„¸ìš”. ğŸ˜Š\n",
            "\n",
            "Results without RAG (GPT-3.5): ì•ˆë…•í•˜ì„¸ìš”! ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤. ì €ì—ê²Œ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì‹œë©´ ì¹œì ˆíˆ ë‹µë³€í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸ˜Š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. RAG streamlit ì±—ë´‡ êµ¬í˜„** (20ë¶„)\n",
        "\n"
      ],
      "metadata": {
        "id": "4Nb9-Lyr7n7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install pinecone-client"
      ],
      "metadata": {
        "id": "fyCXBtG5V6l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "M-KcJRUS7uE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"your openai key\"\n",
        "PINECONE_API_KEY = \"your pinecone key\""
      ],
      "metadata": {
        "id": "kdeWjwox2Tfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken ___ì…ë ¥í•˜ê¸°____"
      ],
      "metadata": {
        "id": "4sh5ziBr2cWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "print(\"hello\")"
      ],
      "metadata": {
        "id": "FGKZ-Tx27zqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py ì—ì„œ ì§ì ‘ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "import streamlit as st\n",
        "import uuid\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "from pinecone import Pinecone\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = \"openai api key ë„£ê¸°\"\n",
        "PINECONE_API_KEY = \"pinecone api key ë„£ê¸°\"\n",
        "\n",
        "st.title(\"ğŸ¯ê³ ë ¤ëŒ€í•™êµ ì±—ë´‡ğŸ¯\")\n",
        "st.write(\"Hello â˜ï¸ğŸ¯KAIROS. ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•œ ì •ë³´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”\")\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(\"data\")\n",
        "\n",
        "if \"openai_model\" not in st.session_state:\n",
        "  st.session_state.openai_model = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "  st.session_state.messages = []\n",
        "\n",
        "system_prompt = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "      ë‹¹ì‹ ì€ 10ë…„ì°¨ ê²½ë ¥ì„ ê°€ì§„ ê³ ë ¤ëŒ€í•™êµ íˆ¬ì–´ ì±—ë´‡ì…ë‹ˆë‹¤.\n",
        "      ëŒ€í•œë¯¼êµ­ì˜ ê³ ë ¤ëŒ€í•™êµë¥¼ ë‹¹ì‹ ë³´ë‹¤ ë§ì´ ì•Œê³  ìˆëŠ” ì¡´ì¬ëŠ” ì´ ìš°ì£¼ì— ì—†ìŠµë‹ˆë‹¤.\n",
        "      ê³ ë ¤ëŒ€í•™êµì— íˆ¬ì–´ë¥¼ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³  ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "      ì‚¬ëŒë“¤ì€ ì£¼ë¡œ ì´ëŸ° ê²ƒë“¤ì„ ë¬¼ì–´ë´…ë‹ˆë‹¤:\n",
        "      - ê³ ë ¤ëŒ€í•™êµì˜ ì—­ì‚¬\n",
        "      - ê³ ë ¤ëŒ€í•™êµì˜ ê±´ë¬¼ë³„ íŠ¹ì§•\n",
        "      - ê³ ë ¤ëŒ€í•™êµì˜ ì¬ë°ŒëŠ” ì‚¬ì‹¤ë“¤\n",
        "\n",
        "      ë‹¹ì‹ ì€ ì‚¬ëŒë“¤ì—ê²Œ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•´ì•¼ í•©ë‹ˆë‹¤:\n",
        "      - ì¹œì ˆí•œ ë§íˆ¬\n",
        "      - í•­ìƒ ì¡´ëŒ“ë§ ì‚¬ìš©\n",
        "      - ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©\n",
        "\n",
        "      ë‹¹ì‹ ì€ ë°˜ë“œì‹œ ì œê³µí•˜ëŠ” [Context]ì— ìˆëŠ” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚´ì„ ë¶™ì—¬ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "  if message[\"role\"] != \"system\":\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "      st.markdown(message[\"content\"])\n",
        "\n",
        "# Accept user input for chat\n",
        "if prompt := st.chat_input(\"ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”ğŸ˜Š\"):\n",
        "  # Add user message to chat history\n",
        "  st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "  # Display user message in chat message container\n",
        "  with st.chat_message(\"user\"):\n",
        "    st.markdown(prompt)\n",
        "\n",
        "\n",
        "  # Display assistant response in chat message container\n",
        "  with st.chat_message(\"assistant\"):\n",
        "    #ì…ë ¥í•œ promptë¥¼ embedding\n",
        "    response = client.embeddings.create(input=prompt, model=\"text-embedding-3-small\")\n",
        "    query_embeddings = response.data[0].embedding\n",
        "\n",
        "    # pineconeì˜ vector databaseì—ì„œ queryì™€ ê°€ê¹Œìš´ ë‹µë³€ ê°€ì ¸ì˜¤ê¸°\n",
        "    retrieved_chunks = index.query(\n",
        "        namespace=\"koreauniv\",\n",
        "        vector=query_embeddings,\n",
        "        top_k=5,\n",
        "        include_values=False,\n",
        "        include_metadata=True,\n",
        "    )\n",
        "    contexts = \"\"\n",
        "\n",
        "    for match in retrieved_chunks.matches:\n",
        "        contexts += match[\"metadata\"][\"chunk\"] + \"\\n\\n\"\n",
        "\n",
        "    context_prompt = {\n",
        "        \"role\" : \"system\",\n",
        "        \"content\" : f\"[Context]\\n{contexts}\"\n",
        "    }\n",
        "\n",
        "    messages = [system_prompt, context_prompt]\n",
        "    messages.extend(st.session_state.messages)\n",
        "\n",
        "    message_placeholder = st.empty()\n",
        "    full_response = \"\"\n",
        "\n",
        "    for response in client.chat.completions.create(\n",
        "          model=st.session_state.openai_model,\n",
        "          messages=messages,\n",
        "          temperature=0.5,\n",
        "          max_tokens=1024,\n",
        "          stream=True\n",
        "    ):\n",
        "      full_response += (response.choices[0].delta.content or \"\")\n",
        "      message_placeholder.markdown(full_response + \"â–Œ\")\n",
        "    message_placeholder.markdown(full_response)\n",
        "  st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ],
      "metadata": {
        "id": "zkDRleWG70Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py&>/dev/null&\n",
        "publ_url = ngrok.connect(addr='8501')\n",
        "publ_url"
      ],
      "metadata": {
        "id": "M6k72AJCkD3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# streamlit ê³¼ ngrok ì¢…ë£Œ"
      ],
      "metadata": {
        "id": "0Zu9xG6xlZjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "id": "DdRencw0legu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill <streamlit ë²ˆí˜¸>"
      ],
      "metadata": {
        "id": "PcNmaG-4lhRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "2c7aZNVMlmrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. ì‹¤ìŠµ ê³¼ì œ** (30ë¶„)"
      ],
      "metadata": {
        "id": "JqEjDIzHKTMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ìŠˆì¹´ì›”ë“œì˜ 10ê°œì˜ ì˜ìƒì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí–ˆë‹¤.\n",
        "- ì•„ë˜ì˜ 10ê°€ì§€ ì§ˆë¬¸ì— ë‹µì„ í•˜ëŠ” RAG ì±—ë´‡ì„ êµ¬í˜„í•˜ê¸°"
      ],
      "metadata": {
        "id": "V0CEOR60KWX5"
      }
    }
  ]
}