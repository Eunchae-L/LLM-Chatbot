{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Function Call**\n",
        "\n",
        "-GPTê°€ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” í•¨ìˆ˜/íˆ´ì— ëŒ€í•´ ì„¤ëª…í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
        "\n",
        "-í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³ \n",
        "\n",
        "-í•¨ìˆ˜ê°€ ì–¸ì œ ì‚¬ìš©ë˜ëŠ”ì§€, í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œ ì–´ë–¤ ì¸ìžê°€ í•„ìš”í•œì§€ JSON Schema í˜•ì‹ìœ¼ë¡œ ì œê³µí•œë‹¤."
      ],
      "metadata": {
        "id": "xSTs-XZD-xmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Callì˜ ë™ìž‘ ìˆœì„œ**\n",
        "\n",
        "1. ìœ ì €ì˜ ì¿¼ë¦¬/ë©”ì‹œì§€ ìž…ë ¥ëœë‹¤.\n",
        "\n",
        "2. GPTëŠ” ìœ ì € ë©”ì‹œì§€ì— ë”°ë¼ íŠ¹ì • í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤ê³  íŒë‹¨í•˜ë©´,\n",
        "\n",
        "ì‹¤í–‰í•  í•¨ìˆ˜ì˜ ì´ë¦„\n",
        "\n",
        "í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•  ë•Œ í•„ìš”í•œ ì¸í’‹(Argument)\n",
        "\n",
        "ë¥¼ ì œê³µí•œë‹¤.\n",
        "\n",
        "3. LLMì´ ì œê³µë°›ì€ í•¨ìˆ˜ ì´ë¦„ê³¼ ì¸ìžë¥¼ í†µí•´ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œë‹¤.\n",
        "\n",
        "4. ì‹¤í–‰ëœ í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ LLMì—ê²Œ ë‹¤ì‹œ ì•Œë ¤ì£¼ê³  ë‹µë³€ì„ ë½‘ì•„ë‚¸ë‹¤.\n",
        "\n",
        "í•µì‹¬: LLMì´ íˆ´ì„ ì‚¬ìš©í•  ë•ŒëŠ” ê¼­ 2ë²ˆì˜ í˜¸ì¶œì´ ì¼ì–´ë‚˜ì•¼ í•œë‹¤!!!"
      ],
      "metadata": {
        "id": "320YfFTK-_sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install openai\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "KPDQL68jaJ_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2di7Hwxpn6OAYj9NchuDCoKosgR_2QejNWzh68Tjn3KfHiWUo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmNdQVaVdJn6",
        "outputId": "9ceb16a2-7367-4180-ac67-3bcfb38d6127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import requests\n",
        "\n",
        "API_KEY = \"\"\n",
        "weather_api_key= \"\"\n",
        "\n",
        "st.title(\"ë‚ ì”¨ë´‡ðŸŒ¤ï¸\")\n",
        "\n",
        "# Set OpenAI API key from Streamlit secrets\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "# Set a default model\n",
        "if \"openai_model\" not in st.session_state:\n",
        "    st.session_state.openai_model = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = [{\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"íŠ¹ì • ì§€ì—­ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ë¬»ëŠ” ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì±—ë´‡ìž…ë‹ˆë‹¤.\\\n",
        "      í•¨ìˆ˜ì— ì—°ê²°í•  ê°’ì„ ê°€ì •í•˜ì§€ ë§ˆì„¸ìš”.\\\n",
        "      ì‚¬ìš©ìžì˜ ìš”ì²­ì´ ëª¨í˜¸í•œ ê²½ìš° ì„¤ëª…ì„ ìš”ì²­í•˜ì„¸ìš”\\\n",
        "      í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì´ëª¨ì§€ë¥¼ ì„žì–´ì„œ ë‹µë³€í•´ì¤˜\"\n",
        "      }]\n",
        "\n",
        "\n",
        "def get_current_weather(location, format):\n",
        "    # Replace 'your_api_key_here' with your actual OpenWeatherMap API key\n",
        "    api_key = weather_api_key\n",
        "    # OpenWeatherMap API endpoint for current weather\n",
        "    base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
        "\n",
        "    # Convert the format to the corresponding unit system for the API request\n",
        "    units = 'metric' if format == 'celsius' else 'imperial'\n",
        "\n",
        "    # Construct the complete API URL with parameters\n",
        "    complete_url = f\"{base_url}appid={api_key}&q={location}&units={units}\"\n",
        "\n",
        "    # Perform the API request\n",
        "    response = requests.get(complete_url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the response JSON\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract relevant weather information\n",
        "        temperature = data['main']['temp']\n",
        "        weather_description = data['weather'][0]['description']\n",
        "\n",
        "        # Construct a result string\n",
        "        result = (f\"'location:{location}, 'temperature':{temperature},'format':{format}, 'weather_description':{weather_description}\")\n",
        "        return result\n",
        "    else:\n",
        "        # Handle possible errors (e.g., location not found)\n",
        "        return \"Weather information could not be retrieved. Please check the location and try again.\"\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather(e.g. temperature, humidity)\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. Seoul(ì„œìš¸), Busan(ë¶€ì‚°).\",\n",
        "                    },\n",
        "                    \"format\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"location\", \"format\"],\n",
        "            },\n",
        "        }\n",
        "    }]\n",
        "\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    if message[\"role\"] != \"system\":\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "# Accept user input for chat\n",
        "if prompt := st.chat_input(\"ë‚ ì”¨ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”\"):\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    # Display user message in chat message container\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    # Display assistant response in chat message container\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        message_placeholder = st.empty()\n",
        "        full_response = \"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=st.session_state.openai_model,\n",
        "            messages=st.session_state.messages,\n",
        "            tools=tools,\n",
        "            )\n",
        "        response_message = response.choices[0].message\n",
        "        function_name = response_message.tool_calls[0].function.name\n",
        "        arguments = json.loads(response_message.tool_calls[0].function.arguments)\n",
        "# í•¨ìˆ˜ì— ì¸ìžê°’ì„ ë„£ì–´ ì‹¤í–‰í•˜ê¸°\n",
        "        function_response = eval(f\"{function_name}(**arguments)\")\n",
        "\n",
        "        st.session_state.messages.append({\n",
        "          \"role\":\"function\",\n",
        "          \"name\":function_name,\n",
        "          \"content\":function_response\n",
        "        })\n",
        "\n",
        "        # ì—¬ê¸°ë¶€í„° ì‹œìž‘í•´ì•¼ ëŒˆë“¯\n",
        "        for response in client.chat.completions.create(\n",
        "            model=st.session_state.openai_model,\n",
        "            messages=st.session_state.messages,\n",
        "            tools = tools,\n",
        "            stream=True,\n",
        "        ):\n",
        "            full_response += (response.choices[0].delta.content or \"\")\n",
        "            message_placeholder.markdown(full_response + \"â–Œ\")\n",
        "        message_placeholder.markdown(full_response)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PChQ01pa9A9",
        "outputId": "5c034def-771e-4824-aeaa-69895d393731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py&>/dev/null&\n",
        "publ_url = ngrok.connect(addr='8501')\n",
        "publ_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J8vz5nndGTR",
        "outputId": "a6d65db1-da19-4163-b5f1-e16e1aa33873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://7ca5-34-125-106-56.ngrok-free.app\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9tMkyqjkcT_",
        "outputId": "08863740-84fe-4ec3-cd62-ffbc89e2df13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 docker-init\n",
            "      6 ?        00:00:03 node\n",
            "     16 ?        00:00:00 oom_monitor.sh\n",
            "     18 ?        00:00:00 run.sh\n",
            "     20 ?        00:00:00 kernel_manager_\n",
            "     22 ?        00:00:00 tail\n",
            "     60 ?        00:00:08 python3 <defunct>\n",
            "     61 ?        00:00:00 colab-fileshim.\n",
            "     83 ?        00:00:04 jupyter-noteboo\n",
            "     84 ?        00:00:00 dap_multiplexer\n",
            "    548 ?        00:00:04 python3\n",
            "    579 ?        00:00:00 python3\n",
            "   1124 ?        00:00:00 language_servic\n",
            "   1129 ?        00:01:08 node\n",
            "   1622 ?        00:00:03 streamlit\n",
            "   1623 ?        00:00:01 ngrok\n",
            "   2268 ?        00:00:00 streamlit\n",
            "   2436 ?        00:00:00 sleep\n",
            "   2437 ?        00:00:00 ps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 2268"
      ],
      "metadata": {
        "id": "DYKbATUSkntK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}